{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Movie Recommmendation with Spark and AWS\n",
    "## Introduction\n",
    "\n",
    "The project uses datasets (ml-latest-small) from [MovieLens](https://grouplens.org/datasets/movielens/latest/), a movie recommendation service. It contains 100836 ratings and 3683 tags across 9742 movies. The ratings were created by 610 users between 1996 and 2018. The larger dataset contains 27753444 ratings and 1108997 tags across 58098 movies. Ratings were created by 283228 users between 1995 and 2018.\n",
    "\n",
    "I also generated two txt files for movies with awards. The file is copied from [Wikipedia/Award-winning films](https://en.wikipedia.org/wiki/List_of_Academy_Award-winning_films)\n",
    "\n",
    "The Project is to build an ETL pipeline that extracts data from S3, processes them using Spark, stages them in Redshift, and transforms data into a set of dimensional tables."
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import boto3\n",
    "import os\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf, col, isnan, when, count, trim, desc, sum, asc\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from pyspark.sql.functions import countDistinct, explode, split, concat_ws, collect_list\n",
    "from pyspark.sql.types import StructType as R, StructField as Fld, DoubleType as Dbl, StringType as Str, IntegerType as Int, DateType as Date\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# STEP 1: Get the params of the created redshift cluster \n",
    "- This is for reading data from S3 to redshift\n",
    "- We need:\n",
    "    - The redshift cluster <font color='red'>endpoint</font>\n",
    "    - The <font color='red'>IAM role ARN</font> that give access to Redshift to read from S3"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "config = configparser.ConfigParser()\n",
    "\n",
    "#Normally this file should be in ~/.aws/credentials\n",
    "config.read_file(open('dwh.cfg'))\n",
    "\n",
    "KEY                    = config.get('AWS','KEY')\n",
    "SECRET                 = config.get('AWS','SECRET')\n",
    "\n",
    "DWH_CLUSTER_TYPE       = config.get(\"DWH\",\"DWH_CLUSTER_TYPE\")\n",
    "DWH_NUM_NODES          = config.get(\"DWH\",\"DWH_NUM_NODES\")\n",
    "DWH_NODE_TYPE          = config.get(\"DWH\",\"DWH_NODE_TYPE\")\n",
    "\n",
    "DWH_CLUSTER_IDENTIFIER = config.get(\"DWH\",\"DWH_CLUSTER_IDENTIFIER\")\n",
    "DWH_DB                 = config.get(\"DWH\",\"DWH_DB\")\n",
    "DWH_DB_USER            = config.get(\"DWH\",\"DWH_DB_USER\")\n",
    "DWH_DB_PASSWORD        = config.get(\"DWH\",\"DWH_DB_PASSWORD\")\n",
    "DWH_PORT               = config.get(\"DWH\",\"DWH_PORT\")\n",
    "\n",
    "DWH_IAM_ROLE_NAME      = config.get(\"DWH\", \"DWH_IAM_ROLE_NAME\")\n",
    "\n",
    "(DWH_DB_USER, DWH_DB_PASSWORD, DWH_DB)\n",
    "\n",
    "pd.DataFrame({\"Param\":\n",
    "                  [\"DWH_CLUSTER_TYPE\", \"DWH_NUM_NODES\", \"DWH_NODE_TYPE\", \"DWH_CLUSTER_IDENTIFIER\", \"DWH_DB\", \"DWH_DB_USER\", \"DWH_DB_PASSWORD\", \"DWH_PORT\", \"DWH_IAM_ROLE_NAME\"],\n",
    "              \"Value\":\n",
    "                  [DWH_CLUSTER_TYPE, DWH_NUM_NODES, DWH_NODE_TYPE, DWH_CLUSTER_IDENTIFIER, DWH_DB, DWH_DB_USER, DWH_DB_PASSWORD, DWH_PORT, DWH_IAM_ROLE_NAME]\n",
    "             })\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]= config['AWS']['KEY']\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]= config['AWS']['SECRET']"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "# e.g. DWH_ENDPOINT=\"redshift-cluster-1.csmamz5zxmle.us-west-2.redshift.amazonaws.com\" \n",
    "DWH_ENDPOINT=\"\" \n",
    "    \n",
    "#e.g DWH_ROLE_ARN=\"arn:aws:iam::988332130976:role/dwhRole\"\n",
    "DWH_ROLE_ARN=\"\""
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2: Explore and Assess the Data using Spark"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "spark = SparkSession.builder\\\n",
    "                     .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:2.7.0\")\\\n",
    "                     .getOrCreate()"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Part 1: Load Data from S3 and clean dataframe\n",
    "- movie.csv: including movieId, title(year), genres\n",
    "  - split title and year from the second column\n",
    "  - split generes from the array\n",
    "- ratings.csv: including userId, movieId, rating, ts\n",
    "  - transform ts string into timestamp\n",
    "- tags.csv: including userId, movieId, tag, ts\n",
    "  - transform ts string into timestamp\n",
    "- awards.txt: including Film, year, awards, nominations\n",
    "  - split txt data using delimiter \"|\"\n",
    "  - identify issues when splitting data like inappropriate year\n",
    "  - transform data into appropriate data type\n",
    "- award_corrected.txt: including Film, year, awards, nominations (corrections for awards.txt)\n",
    "  - join with awards to correct the year\n",
    "  - transform data into appropriate data type"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "movieSchema = R([\n",
    "            Fld(\"movieId\",Int()),\n",
    "            Fld(\"title\",Str()),\n",
    "            Fld(\"genres\",Str())\n",
    "            ])"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "ratingSchema = R([\n",
    "            Fld(\"userId\",Int()),\n",
    "            Fld(\"movieId\",Int()),\n",
    "            Fld(\"rating\",Dbl()),\n",
    "            Fld(\"ts\",Str())\n",
    "            ])"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "tagSchema = R([\n",
    "            Fld(\"userId\",Int()),\n",
    "            Fld(\"movieId\",Int()),\n",
    "            Fld(\"tag\",Str()),\n",
    "            Fld(\"ts\",Str())\n",
    "            ])"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# read movies, ratings, and tags csv\n",
    "dfmovies = spark.read.csv(\"s3a://udacity-input/ml-latest-small/movies.csv\", header=True, schema=movieSchema)\n",
    "dfratings = spark.read.csv(\"s3a://udacity-input/ml-latest-small/ratings.csv\", header = True, schema=ratingSchema)\n",
    "dftags = spark.read.csv(\"s3a://udacity-input/ml-latest-small/tags.csv\", header = True, schema=tagSchema)"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# read awards txt\n",
    "dfawards = spark.read.option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \"|\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"s3a://udacity-input/ml-latest-small/Awards.txt\")\n",
    "\n",
    "dfawards.show(10, truncate=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------------------------------------------+-------+----------+-----------+\n",
      "|Film                                                    |Year   |Awards    |Nominations|\n",
      "+--------------------------------------------------------+-------+----------+-----------+\n",
      "|Parasite                                                |2019.0 |4.0       |6          |\n",
      "|Ford v Ferrari                                          |2019.0 |2.0       |4          |\n",
      "|Learning to Skateboard in a Warzone (If You're a Girl)  |2019.0 |1.0       |1          |\n",
      "|The Neighbors' Window                                   |2019.0 |1.0       |1          |\n",
      "|Little Women                                            |2019.0 |1.0       |6          |\n",
      "|Marriage Story                                          |2019.0 |1.0       |6          |\n",
      "|Jojo Rabbit                                             |2019.0 |1.0       |6          |\n",
      "|Toy Story 4                                             |2019.0 |1.0       |2          |\n",
      "|Joker   2019                                            |2.0    |1.0       |1          |\n",
      "|Once Upon a Time in Hollywood   2019                    |2.0    |1.0       |0          |\n",
      "+--------------------------------------------------------+-------+----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# read award_corrected txt\n",
    "dfawards2 = spark.read.option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \"|\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"s3a://udacity-input/ml-latest-small/Award_corrected.txt\")\n",
    "\n",
    "dfawards2.show(10, truncate=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+-------+----------+-----------+\n",
      "|Film                |Year   |Awards    |Nominations|\n",
      "+--------------------+-------+----------+-----------+\n",
      "|Becket              |1964.0 |1.0       |12         |\n",
      "|Ben-Hur             |1959.0 |11.0      |12         |\n",
      "|Dances with Wolves  |1990.0 |7.0       |12         |\n",
      "|The English Patient |1996.0 |9.0       |12         |\n",
      "|Gladiator           |2000.0 |5.0       |12         |\n",
      "|Johnny Belinda      |1948.0 |1.0       |12         |\n",
      "|Lincoln             |2012.0 |2.0       |12         |\n",
      "|Mrs. Miniver        |1942.0 |6.0       |12         |\n",
      "|My Fair Lady        |1964.0 |8.0       |12         |\n",
      "|On the Waterfront   |1954.0 |8.0       |12         |\n",
      "+--------------------+-------+----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 3: Define Relational Data Model\n",
    "**For the following use cases, I created 5 tables**\n",
    "- number of movies in the dataset  \n",
    "- number of movies in each genre  \n",
    "- number of users in the dataset  \n",
    "- Minimum number of ratings per user  \n",
    "- Minimum number of ratings per movie   \n",
    "- number of movies not rated  \n",
    "- the top 5 movies with high ratings  \n",
    "- number of movies receiving awards  \n",
    "- total awards that movie received  \n",
    "- number of movies rated and receiving awards  \n",
    "- the average rating scores of movies with awards  \n",
    "- year durations in movies, ratings and awards dataset  \n",
    "\n",
    "**snowflake schema**\n",
    "* **awards** - (film, year, nominations, awards)  \n",
    "This table will have the awards that each movie received. The composite key of film and year is used to identify each row in this table since films can be made in the same name. \n",
    "* **movies** - (movieId, title, year)  \n",
    "The primary key for movies is movieId, and genres need to removed from the original table since genres include a list of genres for each movie.\n",
    "* **genres** - (genreId, movieId, genre)  \n",
    "A separate table genres needs to be created to identify the type of each movie. Since each movie can have several types, a unique id genreId is created for this table as primary key.  \n",
    "* **ratings** - (userId, movieId, rating, rate_time, year)  \n",
    "The composite key is userId and movieId in ratings table since a user can rate different movies.\n",
    "* **time** - timestamps in ratings broken down into specific units (date_key, day, week, month, year)\n",
    "A time table is created to check the day, week, month and year. The primary key is date_key.\n",
    "\n",
    "#### Method 1: Mapping Out Data Pipelines using Spark\n",
    "- Movies and genres can be created using the movies csv from S3.\n",
    "- Ratings can be created using the ratings csv from S3.\n",
    "- Awards can be created by joining data in awards.txt and award_correction.txt.\n",
    "\n",
    "#### Method 2: Mapping Out Data Pipelines in Redshift\n",
    "- Awards, ratings, genres table in parquet format can be read directly from S3.  \n",
    "- Movies and genres can be created using the movies data from S3."
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 4: Run Pipelines to Model the Data \n",
    "### 4.1 Create the data model using Spark\n",
    "Build the data pipelines to create the data model."
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "dfmovies.printSchema()\n",
    "dfmovies.show(5, truncate = False)\n",
    "dfmovies.count()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n",
      "+-------+----------------------------------+-------------------------------------------+\n",
      "|movieId|title                             |genres                                     |\n",
      "+-------+----------------------------------+-------------------------------------------+\n",
      "|1      |Toy Story (1995)                  |Adventure|Animation|Children|Comedy|Fantasy|\n",
      "|2      |Jumanji (1995)                    |Adventure|Children|Fantasy                 |\n",
      "|3      |Grumpier Old Men (1995)           |Comedy|Romance                             |\n",
      "|4      |Waiting to Exhale (1995)          |Comedy|Drama|Romance                       |\n",
      "|5      |Father of the Bride Part II (1995)|Comedy                                     |\n",
      "+-------+----------------------------------+-------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9742"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# convert timestamp\n",
    "dfratings = dfratings.withColumn(\n",
    "    \"rate_time\",\n",
    "    F.to_timestamp(F.from_unixtime((col(\"ts\")) , 'yyyy-MM-dd HH:mm:ss.SSS')).cast(\"Timestamp\")\n",
    ").drop(\"ts\")"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "dfratings = dfratings.withColumn(\"year\", F.year(\"rate_time\"))"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "dfratings.printSchema()\n",
    "dfratings.show(5)\n",
    "dfratings.count()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- rate_time: timestamp (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n",
      "+------+-------+------+-------------------+----+\n",
      "|userId|movieId|rating|          rate_time|year|\n",
      "+------+-------+------+-------------------+----+\n",
      "|     1|      1|   4.0|2000-07-30 18:45:03|2000|\n",
      "|     1|      3|   4.0|2000-07-30 18:20:47|2000|\n",
      "|     1|      6|   4.0|2000-07-30 18:37:04|2000|\n",
      "|     1|     47|   5.0|2000-07-30 19:03:35|2000|\n",
      "|     1|     50|   5.0|2000-07-30 18:48:51|2000|\n",
      "+------+-------+------+-------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "100836"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# convert timestamp\n",
    "dftags = dftags.withColumn(\"tag_time\", F.to_timestamp(col(\"ts\") / 1)).drop(\"ts\")\n",
    "dftags = dftags.withColumn(\"year\", F.year(\"tag_time\"))"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "dftags.printSchema()\n",
    "dftags.show(5)\n",
    "dftags.count()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      " |-- tag_time: timestamp (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n",
      "+------+-------+---------------+-------------------+----+\n",
      "|userId|movieId|            tag|           tag_time|year|\n",
      "+------+-------+---------------+-------------------+----+\n",
      "|     2|  60756|          funny|2015-10-24 19:29:54|2015|\n",
      "|     2|  60756|Highly quotable|2015-10-24 19:29:56|2015|\n",
      "|     2|  60756|   will ferrell|2015-10-24 19:29:52|2015|\n",
      "|     2|  89774|   Boxing story|2015-10-24 19:33:27|2015|\n",
      "|     2|  89774|            MMA|2015-10-24 19:33:20|2015|\n",
      "+------+-------+---------------+-------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3683"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "dfawards.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Film   ', 'Year   ', 'Awards    ', 'Nominations']"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# clean awards txt flie\n",
    "dfawards = dfawards.withColumn(\"film\", dfawards['Film   '].cast(Str())).drop('Film   ')\n",
    "dfawards = dfawards.withColumn(\"year\", dfawards['Year   '].cast(Int())).drop(\"Year   \")\n",
    "dfawards = dfawards.withColumn(\"awards\", dfawards['Awards    '].cast(Dbl())).drop(\"Awards    \")\n",
    "dfawards = dfawards.withColumn(\"nominations\", dfawards['Nominations'].cast(Int()))"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "dfawards.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['nominations', 'film', 'year', 'awards']"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "dfawards2.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Film   ', 'Year   ', 'Awards    ', 'Nominations']"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "dfawards2 = dfawards2.withColumn(\"film\", dfawards2['Film   '].cast(Str())).drop('Film   ')\n",
    "dfawards2 = dfawards2.withColumn(\"year\", dfawards2['Year   '].cast(Int())).drop(\"Year   \")\n",
    "#dfawards2 = dfawards2.withColumn(\"date\", F.to_timestamp(col('Year   '))).drop('Year   ')\n",
    "#dfawards2 = dfawards2.withColumn(\"year\", F.year(\"date\")).drop(\"date\")\n",
    "dfawards2 = dfawards2.withColumn(\"awards\", dfawards2['Awards    '].cast(Dbl())).drop(\"Awards    \")\n",
    "dfawards2 = dfawards2.withColumn(\"nominations\", dfawards2['Nominations'].cast(Int()))"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "dfawards.printSchema()\n",
    "dfawards.show(5, truncate = False)\n",
    "dfawards.count()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- nominations: integer (nullable = true)\n",
      " |-- film: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- awards: double (nullable = true)\n",
      "\n",
      "+-----------+--------------------------------------------------------+----+------+\n",
      "|nominations|film                                                    |year|awards|\n",
      "+-----------+--------------------------------------------------------+----+------+\n",
      "|6          |Parasite                                                |2019|4.0   |\n",
      "|4          |Ford v Ferrari                                          |2019|2.0   |\n",
      "|1          |Learning to Skateboard in a Warzone (If You're a Girl)  |2019|1.0   |\n",
      "|1          |The Neighbors' Window                                   |2019|1.0   |\n",
      "|6          |Little Women                                            |2019|1.0   |\n",
      "+-----------+--------------------------------------------------------+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1316"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "dfawards2.printSchema()\n",
    "dfawards2.show(5, truncate = False)\n",
    "dfawards2.count()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- nominations: integer (nullable = true)\n",
      " |-- film: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- awards: double (nullable = true)\n",
      "\n",
      "+-----------+--------------------+----+------+\n",
      "|nominations|film                |year|awards|\n",
      "+-----------+--------------------+----+------+\n",
      "|12         |Becket              |1964|1.0   |\n",
      "|12         |Ben-Hur             |1959|11.0  |\n",
      "|12         |Dances with Wolves  |1990|7.0   |\n",
      "|12         |The English Patient |1996|9.0   |\n",
      "|12         |Gladiator           |2000|5.0   |\n",
      "+-----------+--------------------+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# split the mixed genres by '|'\n",
    "dfmovies2 = dfmovies.withColumn('genre', explode(split(dfmovies.genres, '\\|')))"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "dfmovies2.show(11)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+--------------------+--------------------+---------+\n",
      "|movieId|               title|              genres|    genre|\n",
      "+-------+--------------------+--------------------+---------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|Adventure|\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|Animation|\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...| Children|\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|   Comedy|\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|  Fantasy|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|Adventure|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...| Children|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|  Fantasy|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|   Comedy|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|  Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|   Comedy|\n",
      "+-------+--------------------+--------------------+---------+\n",
      "only showing top 11 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "# create genere information for each movie\n",
    "dfgenre = dfmovies2.select(\"movieId\", \"genre\").dropDuplicates().dropna(subset=[\"movieId\", \"genre\"]).withColumn(\"genreId\", F.monotonically_increasing_id())"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "#dfgenre.filter(dfgenre.title.contains('Toy Story (1995)')).show()\n",
    "dfgenre.filter(dfgenre.movieId == 1).show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+---------+-------------+\n",
      "|movieId|    genre|      genreId|\n",
      "+-------+---------+-------------+\n",
      "|      1|   Comedy|  77309411328|\n",
      "|      1|Adventure| 206158430208|\n",
      "|      1|  Fantasy| 773094113280|\n",
      "|      1| Children|1348619730944|\n",
      "|      1|Animation|1434519076864|\n",
      "+-------+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "dfgenre.columns\n",
    "dfgenre.printSchema()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- genreId: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load Data to S3 in parquet format"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "dfawards.write.parquet(\"s3a://sparkifydend/movies/awards/\", mode=\"overwrite\")"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "dfawards2.write.parquet(\"s3a://sparkifydend/movies/awards2/\", mode=\"overwrite\")"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "dfmovies.write.parquet(\"s3a://sparkifydend/movies/movies/\", mode=\"overwrite\")"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "dfratings.write.parquet(\"s3a://sparkifydend/movies/ratings/\", mode=\"overwrite\")"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "dftags.write.parquet(\"s3a://sparkifydend/movies/tags/\", mode=\"overwrite\")"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "dfgenre.write.parquet(\"s3a://sparkifydend/movies/genres/\", mode=\"overwrite\")"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "dfawards = spark.read.parquet(\"s3a://sparkifydend/movies/awards/*\")\n",
    "dfawards2 = spark.read.parquet(\"s3a://sparkifydend/movies/awards2/*\")\n",
    "dfmovies = spark.read.parquet(\"s3a://sparkifydend/movies/movies/*\")\n",
    "dfratings = spark.read.parquet(\"s3a://sparkifydend/movies/ratings/*\")\n",
    "dftags = spark.read.parquet(\"s3a://sparkifydend/movies/tags/*\")\n",
    "dfgenre = spark.read.parquet(\"s3a://sparkifydend/movies/genres/*\")"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2 Data Quality Checks Part 1: Identify missing values, duplicate data, etc"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "# check for null values\n",
    "dfmovies.select([count(when(col(c).isNull(), c)).alias(c) for c in dfmovies.columns]).show()\n",
    "dfratings.select([count(when(col(c).isNull(), c)).alias(c) for c in dfratings.columns]).show()\n",
    "dfawards.select([count(when(col(c).isNull(), c)).alias(c) for c in dfawards.columns]).show()\n",
    "dfawards2.select([count(when(col(c).isNull(), c)).alias(c) for c in dfawards2.columns]).show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+-----+------+\n",
      "|movieId|title|genres|\n",
      "+-------+-----+------+\n",
      "|      0|    0|     0|\n",
      "+-------+-----+------+\n",
      "\n",
      "+------+-------+------+---------+----+\n",
      "|userId|movieId|rating|rate_time|year|\n",
      "+------+-------+------+---------+----+\n",
      "|     0|      0|     0|        0|   0|\n",
      "+------+-------+------+---------+----+\n",
      "\n",
      "+-----------+----+----+------+\n",
      "|nominations|film|year|awards|\n",
      "+-----------+----+----+------+\n",
      "|          0|   0|   0|     0|\n",
      "+-----------+----+----+------+\n",
      "\n",
      "+-----------+----+----+------+\n",
      "|nominations|film|year|awards|\n",
      "+-----------+----+----+------+\n",
      "|          0|   0|   0|     0|\n",
      "+-----------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "# show records with year < 1920\n",
    "dfawards.filter(dfawards.year < 1920).show(5, truncate = False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+----------------------------------------+----+------+\n",
      "|nominations|film                                    |year|awards|\n",
      "+-----------+----------------------------------------+----+------+\n",
      "|1          |Joker   2019                            |2   |1.0   |\n",
      "|0          |Once Upon a Time in Hollywood   2019    |2   |1.0   |\n",
      "|0          |1917    2019                            |3   |1.0   |\n",
      "|0          |Roma    2018                            |3   |1.0   |\n",
      "|0          |The Favourite   2018                    |1   |1.0   |\n",
      "+-----------+----------------------------------------+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "# check records in dfawards2\n",
    "dfawards2.filter(trim(dfawards2.film) == \"Joker\").show()\n",
    "dfawards2.filter(trim(dfawards2.film) == \"Once Upon a Time in Hollywood\").show()\n",
    "dfawards2.filter(trim(dfawards2.film) == \"1917\").show()\n",
    "dfawards2.filter(trim(dfawards2.film) == \"Roma\").show()\n",
    "dfawards2.filter(trim(dfawards2.film) == \"The Favourite\").show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+--------+----+------+\n",
      "|nominations|    film|year|awards|\n",
      "+-----------+--------+----+------+\n",
      "|         11|Joker   |2019|   2.0|\n",
      "+-----------+--------+----+------+\n",
      "\n",
      "+-----------+--------------------+----+------+\n",
      "|nominations|                film|year|awards|\n",
      "+-----------+--------------------+----+------+\n",
      "|         10|Once Upon a Time ...|2019|   2.0|\n",
      "+-----------+--------------------+----+------+\n",
      "\n",
      "+-----------+--------+----+------+\n",
      "|nominations|    film|year|awards|\n",
      "+-----------+--------+----+------+\n",
      "|         10|1917    |2019|   3.0|\n",
      "+-----------+--------+----+------+\n",
      "\n",
      "+-----------+--------+----+------+\n",
      "|nominations|    film|year|awards|\n",
      "+-----------+--------+----+------+\n",
      "|         10|Roma    |2018|   3.0|\n",
      "+-----------+--------+----+------+\n",
      "\n",
      "+-----------+----------------+----+------+\n",
      "|nominations|            film|year|awards|\n",
      "+-----------+----------------+----+------+\n",
      "|         10|The Favourite   |2018|   1.0|\n",
      "+-----------+----------------+----+------+\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "# drop records with wrong year \n",
    "dfawards = dfawards.filter(dfawards.year > 1920)"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "dfawards.select([count(when(col(c).isNull(), c)).alias(c) for c in dfawards.columns]).show()\n",
    "dfawards.show(5, truncate = False)\n",
    "dfawards.count()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+----+----+------+\n",
      "|nominations|film|year|awards|\n",
      "+-----------+----+----+------+\n",
      "|          0|   0|   0|     0|\n",
      "+-----------+----+----+------+\n",
      "\n",
      "+-----------+--------------------------------------------------------+----+------+\n",
      "|nominations|film                                                    |year|awards|\n",
      "+-----------+--------------------------------------------------------+----+------+\n",
      "|6          |Parasite                                                |2019|4.0   |\n",
      "|4          |Ford v Ferrari                                          |2019|2.0   |\n",
      "|1          |Learning to Skateboard in a Warzone (If You're a Girl)  |2019|1.0   |\n",
      "|1          |The Neighbors' Window                                   |2019|1.0   |\n",
      "|6          |Little Women                                            |2019|1.0   |\n",
      "+-----------+--------------------------------------------------------+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1247"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "# union dfawards and dfawards2, and remove duplicates\n",
    "# dfawards2 has corrections for year\n",
    "dfawards3 = dfawards.union(dfawards2).distinct().filter(~col(\"year\").isin([0]) & col(\"year\").isNotNull()).sort(desc('year'))\n",
    "dfawards3.show(5, truncate = False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+--------------------------------------------------------+----+------+\n",
      "|nominations|film                                                    |year|awards|\n",
      "+-----------+--------------------------------------------------------+----+------+\n",
      "|4          |Ford v Ferrari                                          |2019|2.0   |\n",
      "|1          |Learning to Skateboard in a Warzone (If You're a Girl)  |2019|1.0   |\n",
      "|11         |Joker                                                   |2019|2.0   |\n",
      "|6          |Parasite                                                |2019|4.0   |\n",
      "|1          |Rocketman                                               |2019|1.0   |\n",
      "+-----------+--------------------------------------------------------+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "# show records with year not in the right range\n",
    "dfawards3.where(dfawards3.year < 1920).show(5, truncate = False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+----+----+------+\n",
      "|nominations|film|year|awards|\n",
      "+-----------+----+----+------+\n",
      "+-----------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "# load to S3\n",
    "dfawards3.write.parquet(\"s3a://sparkifydend/movies/awards3/\", mode=\"overwrite\")"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2 Data Quality Checks Part 2: source/count checks to ensure completeness"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "def quality_check(df, tablename):\n",
    "    '''\n",
    "    Input: Spark dataframe, table name\n",
    "    Output: Print outcome of data quality check\n",
    "    '''\n",
    "    \n",
    "    result = df.count()\n",
    "    if result == 0:\n",
    "        print(\"Data quality check failed for {} with zero records\".format(tablename))\n",
    "    else:\n",
    "        print(\"Data quality check passed for {} with {} records\".format(tablename, result))\n",
    "    return 0"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "# Perform data quality check with unit test\n",
    "quality_check(dfmovies, \"movies table\")\n",
    "quality_check(dfratings, \"ratings table\")\n",
    "quality_check(dfawards3, \"awards table\")\n",
    "quality_check(dfgenre, \"genre table\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data quality check passed for movies table with 9742 records\n",
      "Data quality check passed for ratings table with 100836 records\n",
      "Data quality check passed for awards table with 1316 records\n",
      "Data quality check passed for genre table with 22084 records\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "dfmovies.count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9742"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "dfmovies[['movieId']].drop_duplicates().count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9742"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "dfratings.count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "100836"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "# dfratings is on movieid and userid level\n",
    "dfratings[['movieId', 'userId']].drop_duplicates().count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "100836"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "dfawards3.count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1316"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "# dfawards3 is on title and year level\n",
    "dfawards3[['film', 'year']].drop_duplicates().count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1316"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "# check out movies with same name\n",
    "df1 = dfawards3.groupBy(\"film\").count().filter(\"count > 1\")\n",
    "df1.show(truncate = False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------------------+-----+\n",
      "|film                    |count|\n",
      "+------------------------+-----+\n",
      "|Cyrano de Bergerac      |2    |\n",
      "|King Kong               |2    |\n",
      "|Henry V                 |2    |\n",
      "|A Star Is Born          |3    |\n",
      "|Little Women            |3    |\n",
      "|The Great Gatsby        |2    |\n",
      "|The Old Man and the Sea |2    |\n",
      "|Titanic                 |2    |\n",
      "|Up                      |2    |\n",
      "|Cleopatra               |2    |\n",
      "+------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "dfawards3.filter(trim(dfawards3.film) == \"A Star Is Born\").show()\n",
    "dfawards3.filter(trim(dfawards3.film) == \"Titanic\").show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+----------------+----+------+\n",
      "|nominations|            film|year|awards|\n",
      "+-----------+----------------+----+------+\n",
      "|          8|A Star Is Born  |2018|   1.0|\n",
      "|          4|A Star Is Born  |1976|   1.0|\n",
      "|          7|A Star Is Born  |1937|   1.0|\n",
      "+-----------+----------------+----+------+\n",
      "\n",
      "+-----------+--------+----+------+\n",
      "|nominations|    film|year|awards|\n",
      "+-----------+--------+----+------+\n",
      "|         14|Titanic |1997|  11.0|\n",
      "|          2|Titanic |1953|   1.0|\n",
      "+-----------+--------+----+------+\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.3 Data Wrangling with Spark and OLAP"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "# use the dataframe dfmovies2 to match every movie to a single genre\n",
    "genre_movies = dfmovies2 \\\n",
    "                    .groupBy(dfmovies2.genre) \\\n",
    "                    .agg(concat_ws(',', collect_list(dfmovies2.movieId)) \\\n",
    "                    .alias('MovieIds')) \\\n",
    "                    .orderBy('genre')"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "genre_movies.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------------+--------------------+\n",
      "|             genre|            MovieIds|\n",
      "+------------------+--------------------+\n",
      "|(no genres listed)|114335,122888,122...|\n",
      "|            Action|6,9,10,15,20,23,4...|\n",
      "|         Adventure|1,2,8,10,13,15,29...|\n",
      "|         Animation|1,13,48,239,313,3...|\n",
      "|          Children|1,2,8,13,27,34,38...|\n",
      "|            Comedy|1,3,4,5,7,11,12,1...|\n",
      "|             Crime|6,16,20,21,22,23,...|\n",
      "|       Documentary|77,99,108,116,128...|\n",
      "|             Drama|4,11,14,16,17,20,...|\n",
      "|           Fantasy|1,2,29,44,60,126,...|\n",
      "|         Film-Noir|164,320,347,913,9...|\n",
      "|            Horror|12,22,70,92,93,15...|\n",
      "|              IMAX|150,364,595,1797,...|\n",
      "|           Musical|48,107,199,242,34...|\n",
      "|           Mystery|22,29,32,47,50,10...|\n",
      "|           Romance|3,4,7,11,15,17,25...|\n",
      "|            Sci-Fi|24,29,32,66,76,10...|\n",
      "|          Thriller|6,10,20,21,22,23,...|\n",
      "|               War|41,73,110,151,155...|\n",
      "|           Western|163,210,266,303,3...|\n",
      "+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "# use case\n",
    "# number of movies in the dataset\n",
    "distinct_movie = dfmovies.select(\"movieId\").distinct().count()\n",
    "print('{} movies in the movies dataset'.format(distinct_movie))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9742 movies in the movies dataset\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "# number of users in the dataset\n",
    "distinct_user = dfratings.select(\"userId\").distinct().count()\n",
    "print('{} users rated the movies'.format(distinct_user))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "610 users rated the movies\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "# number of movies receiving awards\n",
    "distinct_award = dfawards3.select(\"film\", \"year\").distinct().count()\n",
    "print('{} movies received awards'.format(distinct_award))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1316 movies received awards\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "# show movies receiving more than 10 awards\n",
    "dfawards3.where(dfawards3.awards > 10).show(truncate = False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+------------------------------------------------+----+------+\n",
      "|nominations|film                                            |year|awards|\n",
      "+-----------+------------------------------------------------+----+------+\n",
      "|11         |The Lord of the Rings: The Return of the King   |2003|11.0  |\n",
      "|14         |Titanic                                         |1997|11.0  |\n",
      "|12         |Ben-Hur                                         |1959|11.0  |\n",
      "+-----------+------------------------------------------------+----+------+\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "# total awards that movie received\n",
    "awards_cnt = dfawards3.groupBy(\"film\", \"year\").agg(F.sum(\"awards\").alias('cnt')).orderBy(desc('cnt'))"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "awards_cnt.show(truncate = False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------------------------------------------+----+----+\n",
      "|film                                            |year|cnt |\n",
      "+------------------------------------------------+----+----+\n",
      "|Titanic                                         |1997|11.0|\n",
      "|Ben-Hur                                         |1959|11.0|\n",
      "|The Lord of the Rings: The Return of the King   |2003|11.0|\n",
      "|West Side Story                                 |1961|10.0|\n",
      "|The English Patient                             |1996|9.0 |\n",
      "|The Last Emperor                                |1987|9.0 |\n",
      "|Gigi                                            |1958|9.0 |\n",
      "|From Here to Eternity                           |1953|8.0 |\n",
      "|Cabaret                                         |1972|8.0 |\n",
      "|Gandhi                                          |1982|8.0 |\n",
      "|On the Waterfront                               |1954|8.0 |\n",
      "|Amadeus                                         |1984|8.0 |\n",
      "|My Fair Lady                                    |1964|8.0 |\n",
      "|Slumdog Millionaire                             |2008|8.0 |\n",
      "|Gone with the Wind                              |1939|8.0 |\n",
      "|Gravity                                         |2013|7.0 |\n",
      "|Shakespeare in Love                             |1998|7.0 |\n",
      "|Out of Africa                                   |1985|7.0 |\n",
      "|Patton                                          |1970|7.0 |\n",
      "|Schindler's List                                |1993|7.0 |\n",
      "+------------------------------------------------+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "# Minimum number of ratings per user\n",
    "# Minimum number of ratings per movie \n",
    "tmp1 = dfratings.groupBy(\"userID\").count().toPandas()['count'].min()\n",
    "tmp2 = dfratings.groupBy(\"movieId\").count().toPandas()['count'].min()\n",
    "print('For the users that rated movies and the movies that were rated:')\n",
    "print('Minimum number of ratings per user is {}'.format(tmp1))\n",
    "print('Minimum number of ratings per movie is {}'.format(tmp2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For the users that rated movies and the movies that were rated:\n",
      "Minimum number of ratings per user is 20\n",
      "Minimum number of ratings per movie is 1\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "# count number of movies in each genre\n",
    "# The top three genres are drama, comedy, and thriller\n",
    "df2=dfmovies2.groupBy(\"genre\").count().filter(trim(dfmovies2.genre) != '(no genres listed)').sort(desc('count'))\n",
    "df2.show(truncate = False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+-----+\n",
      "|genre      |count|\n",
      "+-----------+-----+\n",
      "|Drama      |4361 |\n",
      "|Comedy     |3756 |\n",
      "|Thriller   |1894 |\n",
      "|Action     |1828 |\n",
      "|Romance    |1596 |\n",
      "|Adventure  |1263 |\n",
      "|Crime      |1199 |\n",
      "|Sci-Fi     |980  |\n",
      "|Horror     |978  |\n",
      "|Fantasy    |779  |\n",
      "|Children   |664  |\n",
      "|Animation  |611  |\n",
      "|Mystery    |573  |\n",
      "|Documentary|440  |\n",
      "|War        |382  |\n",
      "|Musical    |334  |\n",
      "|Western    |167  |\n",
      "|IMAX       |158  |\n",
      "|Film-Noir  |87   |\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "dfratings.createOrReplaceTempView(\"ratings\")     #userId, movieId, rating, rate_time, year\n",
    "dfmovies.createOrReplaceTempView(\"movies\")       #movieId, title, genre\n",
    "dftags.createOrReplaceTempView(\"tags\")           #userId, movieId, tag, tag_time, year\n",
    "dfawards3.createOrReplaceTempView(\"awards\")      #nominations, film, year, awards\n",
    "dfgenre.createOrReplaceTempView(\"genres\")        #genreId, genre, movieId"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "# Split title and release year in separate columns     \n",
    "movies = spark.sql(\"select movieId, substr(title, 0, length(title)-7) as title, substr(title, -5, 4) as year from movies\")\n",
    "movies.show()\n",
    "movies.createOrReplaceTempView(\"movies\") "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+--------------------+----+\n",
      "|movieId|               title|year|\n",
      "+-------+--------------------+----+\n",
      "|      1|           Toy Story|1995|\n",
      "|      2|             Jumanji|1995|\n",
      "|      3|    Grumpier Old Men|1995|\n",
      "|      4|   Waiting to Exhale|1995|\n",
      "|      5|Father of the Bri...|1995|\n",
      "|      6|                Heat|1995|\n",
      "|      7|             Sabrina|1995|\n",
      "|      8|        Tom and Huck|1995|\n",
      "|      9|        Sudden Death|1995|\n",
      "|     10|           GoldenEye|1995|\n",
      "|     11|American Presiden...|1995|\n",
      "|     12|Dracula: Dead and...|1995|\n",
      "|     13|               Balto|1995|\n",
      "|     14|               Nixon|1995|\n",
      "|     15|    Cutthroat Island|1995|\n",
      "|     16|              Casino|1995|\n",
      "|     17|Sense and Sensibi...|1995|\n",
      "|     18|          Four Rooms|1995|\n",
      "|     19|Ace Ventura: When...|1995|\n",
      "|     20|         Money Train|1995|\n",
      "+-------+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "# year of movies in the dataset\n",
    "spark.sql(\"\"\"select \n",
    "             min(year) as min_year,\n",
    "             max(year) as max_year\n",
    "             from movies \n",
    "             where year > 0\n",
    "\"\"\").show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------+--------+\n",
      "|min_year|max_year|\n",
      "+--------+--------+\n",
      "|    1902|    2018|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "# year of rating in the dataset\n",
    "spark.sql(\"\"\"select \n",
    "             min(year) as min_year,\n",
    "             max(year) as max_year\n",
    "             from ratings\n",
    "\"\"\").show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------+--------+\n",
      "|min_year|max_year|\n",
      "+--------+--------+\n",
      "|    1996|    2018|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "# year of awards in the dataset\n",
    "spark.sql(\"\"\"select \n",
    "             min(year) as min_year,\n",
    "             max(year) as max_year\n",
    "             from awards\n",
    "\"\"\").show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------+--------+\n",
      "|min_year|max_year|\n",
      "+--------+--------+\n",
      "|    1927|    2019|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "# number of movies not rated\n",
    "spark.sql(\"\"\"select \n",
    "          count(distinct movies.movieId)\n",
    "          from movies \n",
    "          where movies.movieId not in\n",
    "          (select distinct ratings.movieId from ratings)\n",
    "          \"\"\").show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------------------+\n",
      "|count(DISTINCT movieId)|\n",
      "+-----------------------+\n",
      "|                     18|\n",
      "+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "# number of movies rated and receiving awards\n",
    "# 474 movies receiving awards and shown in ratings dataset\n",
    "spark.sql(\"\"\"select count(distinct movieId) as in_ratings from \n",
    "          (select distinct a.film, a.year, m.movieId as movieId\n",
    "          from awards as a inner join movies as m on trim(a.film) == trim(m.title) and a.year = m.year\n",
    "          where a.year > 0 and m.year > 0) t\n",
    "          where movieId in \n",
    "          (select distinct ratings.movieId from ratings)\n",
    "          \"\"\").show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+\n",
      "|in_ratings|\n",
      "+----------+\n",
      "|       474|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "# the top 5 movies with high ratings\n",
    "avg_rating = spark.sql(\"\"\"select distinct\n",
    "    m.title as title,\n",
    "    m.year as year,\n",
    "    sum(case when r.rating >= 0 then 1 else 0 end) as num_rating,\n",
    "    avg(r.rating) as avg_rating\n",
    "    from movies as m inner join ratings as r on m.movieId = r.movieId\n",
    "    group by m.title, m.year\n",
    "    order by avg_rating desc\n",
    "\"\"\")\n",
    "avg_rating.show(5)\n",
    "avg_rating.createOrReplaceTempView(\"avg_rating\") "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+----+----------+----------+\n",
      "|               title|year|num_rating|avg_rating|\n",
      "+--------------------+----+----------+----------+\n",
      "|SORI: Voice from ...|2016|         1|       5.0|\n",
      "|National Lampoon'...|2007|         1|       5.0|\n",
      "|      Blue Planet II|2017|         1|       5.0|\n",
      "|                9/11|2002|         1|       5.0|\n",
      "|Sun Alley (Sonnen...|1999|         1|       5.0|\n",
      "+--------------------+----+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "# total awards for each movie\n",
    "tot_awards = spark.sql(\"\"\"select distinct\n",
    "                    film,\n",
    "                    year,\n",
    "                    sum(awards) as tot_awards\n",
    "                    from awards\n",
    "                    group by film, year\n",
    "                    order by tot_awards desc\n",
    "\"\"\")\n",
    "tot_awards.show(5)\n",
    "tot_awards.createOrReplaceTempView(\"tot_awards\") "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+----+----------+\n",
      "|                film|year|tot_awards|\n",
      "+--------------------+----+----------+\n",
      "|The Lord of the R...|2003|      11.0|\n",
      "|            Titanic |1997|      11.0|\n",
      "|            Ben-Hur |1959|      11.0|\n",
      "|    West Side Story |1961|      10.0|\n",
      "|The Last Emperor    |1987|       9.0|\n",
      "+--------------------+----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "# the average rating scores of movies with awards\n",
    "movie_awards_rating = spark.sql(\"\"\"select distinct\n",
    "             a.film,\n",
    "             a.year,\n",
    "             a.tot_awards,\n",
    "             r.avg_rating\n",
    "             from tot_awards as a inner join avg_rating as r on trim(a.film) == trim(r.title) and a.year == r.year\n",
    "             where a.year > 0 and r.year > 0\n",
    "             order by tot_awards desc, avg_rating desc\n",
    "\"\"\")\n",
    "movie_awards_rating.show(truncate = False)\n",
    "movie_awards_rating.createOrReplaceTempView(\"movie_awards_rating\") "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------------------+----+----------+------------------+\n",
      "|film                    |year|tot_awards|avg_rating        |\n",
      "+------------------------+----+----------+------------------+\n",
      "|Ben-Hur                 |1959|11.0      |3.9411764705882355|\n",
      "|Titanic                 |1997|11.0      |3.414285714285714 |\n",
      "|West Side Story         |1961|10.0      |3.6029411764705883|\n",
      "|Gigi                    |1958|9.0       |3.25              |\n",
      "|On the Waterfront       |1954|8.0       |4.1875            |\n",
      "|Amadeus                 |1984|8.0       |4.184210526315789 |\n",
      "|My Fair Lady            |1964|8.0       |4.042857142857143 |\n",
      "|From Here to Eternity   |1953|8.0       |3.9545454545454546|\n",
      "|Gandhi                  |1982|8.0       |3.8333333333333335|\n",
      "|Slumdog Millionaire     |2008|8.0       |3.8098591549295775|\n",
      "|Gone with the Wind      |1939|8.0       |3.6444444444444444|\n",
      "|Cabaret                 |1972|8.0       |3.0               |\n",
      "|Lawrence of Arabia      |1962|7.0       |4.3               |\n",
      "|Schindler's List        |1993|7.0       |4.225             |\n",
      "|Patton                  |1970|7.0       |4.121212121212121 |\n",
      "|Dances with Wolves      |1990|7.0       |3.8353658536585367|\n",
      "|Shakespeare in Love     |1998|7.0       |3.777173913043478 |\n",
      "|Out of Africa           |1985|7.0       |3.6666666666666665|\n",
      "|Gravity                 |2013|7.0       |3.578125          |\n",
      "|Going My Way            |1944|7.0       |3.25              |\n",
      "+------------------------+----+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "spark.sql(\"select count(*) from tot_awards\").show()\n",
    "spark.sql(\"select count(*) from avg_rating\").show()\n",
    "spark.sql(\"select count(*) from movie_awards_rating\").show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    1316|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    9719|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     473|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.4 Create the data model using Redshift\n",
    "Build the data pipelines to create the data model."
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Extract parquet data from S3 and transform into fact and dimension tables"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "s3 = boto3.resource('s3',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                     )\n",
    "\n",
    "s3bucket =  s3.Bucket(\"udacity-input\") # private\n",
    "\n",
    "s3_data = iter(s3bucket.objects.filter(Prefix=\"ml-latest-small/\"))\n",
    "for _ in range(5): print(next(s3_data))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "s3.ObjectSummary(bucket_name='udacity-input', key='ml-latest-small/')\n",
      "s3.ObjectSummary(bucket_name='udacity-input', key='ml-latest-small/Award_corrected.txt')\n",
      "s3.ObjectSummary(bucket_name='udacity-input', key='ml-latest-small/Awards.txt')\n",
      "s3.ObjectSummary(bucket_name='udacity-input', key='ml-latest-small/README.txt')\n",
      "s3.ObjectSummary(bucket_name='udacity-input', key='ml-latest-small/links.csv')\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "%load_ext sql"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DWH_DB_USER, DWH_DB_PASSWORD, DWH_ENDPOINT, DWH_PORT,DWH_DB)\n",
    "print(conn_string)\n",
    "%sql $conn_string"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "postgresql://dwhadmin:Pika1324_@dwhcluster.cdqvmxgabrab.us-west-2.redshift.amazonaws.com:5439/dev\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Connected: dwhadmin@dev'"
      ]
     },
     "metadata": {},
     "execution_count": 125
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### copy data from s3 to redshift"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "source": [
    "%%time\n",
    "\n",
    "qry = \"\"\"\n",
    "    copy dimRatings from 's3://sparkifydend/movies/ratings/' \n",
    "    credentials 'aws_iam_role={}'\n",
    "    FORMAT AS PARQUET;\n",
    "\"\"\".format(DWH_ROLE_ARN)\n",
    "\n",
    "%sql $qry"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * postgresql://dwhadmin:***@dwhcluster.cdqvmxgabrab.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "Done.\n",
      "CPU times: user 4.39 ms, sys: 0 ns, total: 4.39 ms\n",
      "Wall time: 912 ms\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "source": [
    "%sql select * from dimRatings limit 5;"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * postgresql://dwhadmin:***@dwhcluster.cdqvmxgabrab.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "5 rows affected.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>userid</th>\n",
       "        <th>movieid</th>\n",
       "        <th>rating</th>\n",
       "        <th>rate_time</th>\n",
       "        <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>1</td>\n",
       "        <td>4.0</td>\n",
       "        <td>2000-07-30 18:45:03</td>\n",
       "        <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>151</td>\n",
       "        <td>5.0</td>\n",
       "        <td>2000-07-30 19:07:21</td>\n",
       "        <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>296</td>\n",
       "        <td>3.0</td>\n",
       "        <td>2000-07-30 18:49:27</td>\n",
       "        <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>441</td>\n",
       "        <td>4.0</td>\n",
       "        <td>2000-07-30 18:14:28</td>\n",
       "        <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>590</td>\n",
       "        <td>4.0</td>\n",
       "        <td>2000-07-30 18:42:26</td>\n",
       "        <td>2000</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(1, 1, 4.0, datetime.datetime(2000, 7, 30, 18, 45, 3), 2000),\n",
       " (1, 151, 5.0, datetime.datetime(2000, 7, 30, 19, 7, 21), 2000),\n",
       " (1, 296, 3.0, datetime.datetime(2000, 7, 30, 18, 49, 27), 2000),\n",
       " (1, 441, 4.0, datetime.datetime(2000, 7, 30, 18, 14, 28), 2000),\n",
       " (1, 590, 4.0, datetime.datetime(2000, 7, 30, 18, 42, 26), 2000)]"
      ]
     },
     "metadata": {},
     "execution_count": 209
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "source": [
    "%sql select count(*) from dimRatings;"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * postgresql://dwhadmin:***@dwhcluster.cdqvmxgabrab.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "1 rows affected.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>100836</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(100836,)]"
      ]
     },
     "metadata": {},
     "execution_count": 210
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### check the stl_load_errors table"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "source": [
    "%%sql\n",
    "select query, substring(filename,22,25) as filename,line_number as line, \n",
    "substring(colname,0,12) as column, type, position as pos, substring(raw_line,0,30) as line_text,\n",
    "substring(raw_field_value,0,15) as field_text, \n",
    "substring(err_reason,0,45) as reason\n",
    "from stl_load_errors \n",
    "order by query desc\n",
    "limit 10;"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * postgresql://dwhadmin:***@dwhcluster.cdqvmxgabrab.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "10 rows affected.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>query</th>\n",
       "        <th>filename</th>\n",
       "        <th>line</th>\n",
       "        <th>column</th>\n",
       "        <th>type</th>\n",
       "        <th>pos</th>\n",
       "        <th>line_text</th>\n",
       "        <th>field_text</th>\n",
       "        <th>reason</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3548</td>\n",
       "        <td>-latest-small/ratings.csv</td>\n",
       "        <td>2</td>\n",
       "        <td>rate_time</td>\n",
       "        <td>timestamp </td>\n",
       "        <td>8</td>\n",
       "        <td>1,1,4.0,964982703</td>\n",
       "        <td>964982703</td>\n",
       "        <td>Invalid timestamp format or value [YYYY-MM-D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3227</td>\n",
       "        <td>-latest-small/ratings.csv</td>\n",
       "        <td>2</td>\n",
       "        <td>rate_time</td>\n",
       "        <td>timestamp </td>\n",
       "        <td>8</td>\n",
       "        <td>1,1,4.0,964982703</td>\n",
       "        <td>964982703</td>\n",
       "        <td>Invalid timestamp format or value [YYYY-MM-D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3115</td>\n",
       "        <td>-latest-small/ratings.csv</td>\n",
       "        <td>2</td>\n",
       "        <td>rate_time</td>\n",
       "        <td>timestamp </td>\n",
       "        <td>8</td>\n",
       "        <td>1,1,4.0,964982703</td>\n",
       "        <td>964982703</td>\n",
       "        <td>Invalid data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3095</td>\n",
       "        <td>-latest-small/ratings.csv</td>\n",
       "        <td>2</td>\n",
       "        <td>rate_time</td>\n",
       "        <td>timestamp </td>\n",
       "        <td>8</td>\n",
       "        <td>1,1,4.0,964982703</td>\n",
       "        <td>964982703</td>\n",
       "        <td>Invalid timestamp format or value [YYYY-MM-D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3080</td>\n",
       "        <td>-latest-small/ratings.csv</td>\n",
       "        <td>2</td>\n",
       "        <td>rate_time</td>\n",
       "        <td>timestamp </td>\n",
       "        <td>8</td>\n",
       "        <td>1,1,4.0,964982703</td>\n",
       "        <td>964982703</td>\n",
       "        <td>Invalid timestamp format or value [YYYY-MM-D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3058</td>\n",
       "        <td>-latest-small/ratings.csv</td>\n",
       "        <td>2</td>\n",
       "        <td>rate_time</td>\n",
       "        <td>timestamp </td>\n",
       "        <td>8</td>\n",
       "        <td>1,1,4.0,964982703</td>\n",
       "        <td>964982703</td>\n",
       "        <td>Invalid data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3020</td>\n",
       "        <td>-latest-small/ratings.csv</td>\n",
       "        <td>2</td>\n",
       "        <td>rate_time</td>\n",
       "        <td>timestamp </td>\n",
       "        <td>8</td>\n",
       "        <td>1,1,4.0,964982703</td>\n",
       "        <td>964982703</td>\n",
       "        <td>Invalid timestamp format or value [YYYY-MM-D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2975</td>\n",
       "        <td>-latest-small/ratings.csv</td>\n",
       "        <td>2</td>\n",
       "        <td>rate_time</td>\n",
       "        <td>timestamp </td>\n",
       "        <td>8</td>\n",
       "        <td>1,1,4.0,964982703</td>\n",
       "        <td>964982703</td>\n",
       "        <td>Invalid data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2900</td>\n",
       "        <td>-latest-small/ratings.csv</td>\n",
       "        <td>2</td>\n",
       "        <td>rate_time</td>\n",
       "        <td>timestamp </td>\n",
       "        <td>8</td>\n",
       "        <td>1,1,4.0,964982703</td>\n",
       "        <td>964982703</td>\n",
       "        <td>Invalid timestamp format or value [YYYY-MM-D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2880</td>\n",
       "        <td>-latest-small/ratings.csv</td>\n",
       "        <td>2</td>\n",
       "        <td>rate_time</td>\n",
       "        <td>timestamp </td>\n",
       "        <td>8</td>\n",
       "        <td>1,1,4.0,964982703</td>\n",
       "        <td>964982703</td>\n",
       "        <td>Invalid timestamp format or value [YYYY-MM-D</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(3548, '-latest-small/ratings.csv', 2, 'rate_time', 'timestamp ', 8, '1,1,4.0,964982703', '964982703', 'Invalid timestamp format or value [YYYY-MM-D'),\n",
       " (3227, '-latest-small/ratings.csv', 2, 'rate_time', 'timestamp ', 8, '1,1,4.0,964982703', '964982703', 'Invalid timestamp format or value [YYYY-MM-D'),\n",
       " (3115, '-latest-small/ratings.csv', 2, 'rate_time', 'timestamp ', 8, '1,1,4.0,964982703', '964982703', 'Invalid data'),\n",
       " (3095, '-latest-small/ratings.csv', 2, 'rate_time', 'timestamp ', 8, '1,1,4.0,964982703', '964982703', 'Invalid timestamp format or value [YYYY-MM-D'),\n",
       " (3080, '-latest-small/ratings.csv', 2, 'rate_time', 'timestamp ', 8, '1,1,4.0,964982703', '964982703', 'Invalid timestamp format or value [YYYY-MM-D'),\n",
       " (3058, '-latest-small/ratings.csv', 2, 'rate_time', 'timestamp ', 8, '1,1,4.0,964982703', '964982703', 'Invalid data'),\n",
       " (3020, '-latest-small/ratings.csv', 2, 'rate_time', 'timestamp ', 8, '1,1,4.0,964982703', '964982703', 'Invalid timestamp format or value [YYYY-MM-D'),\n",
       " (2975, '-latest-small/ratings.csv', 2, 'rate_time', 'timestamp ', 8, '1,1,4.0,964982703', '964982703', 'Invalid data'),\n",
       " (2900, '-latest-small/ratings.csv', 2, 'rate_time', 'timestamp ', 8, '1,1,4.0,964982703', '964982703', 'Invalid timestamp format or value [YYYY-MM-D'),\n",
       " (2880, '-latest-small/ratings.csv', 2, 'rate_time', 'timestamp ', 8, '1,1,4.0,964982703', '964982703', 'Invalid timestamp format or value [YYYY-MM-D')]"
      ]
     },
     "metadata": {},
     "execution_count": 211
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "source": [
    "%%time\n",
    "\n",
    "qry = \"\"\"\n",
    "    copy dimAwards3 from 's3://sparkifydend/movies/awards3/' \n",
    "    credentials 'aws_iam_role={}' \n",
    "    FORMAT AS PARQUET;\n",
    "\"\"\".format(DWH_ROLE_ARN)\n",
    "\n",
    "%sql $qry"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * postgresql://dwhadmin:***@dwhcluster.cdqvmxgabrab.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "Done.\n",
      "CPU times: user 4.62 ms, sys: 0 ns, total: 4.62 ms\n",
      "Wall time: 1.2 s\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "source": [
    "%sql select * from dimAwards3 limit 5;"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * postgresql://dwhadmin:***@dwhcluster.cdqvmxgabrab.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "5 rows affected.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>nominations</th>\n",
       "        <th>film</th>\n",
       "        <th>year</th>\n",
       "        <th>awards</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>7</td>\n",
       "        <td>Sons and Lovers </td>\n",
       "        <td>1960</td>\n",
       "        <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>Day of the Painter  </td>\n",
       "        <td>1960</td>\n",
       "        <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3</td>\n",
       "        <td>The Empire Strikes Back </td>\n",
       "        <td>1980</td>\n",
       "        <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>8</td>\n",
       "        <td>Raging Bull </td>\n",
       "        <td>1980</td>\n",
       "        <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>6</td>\n",
       "        <td>Mystic River    </td>\n",
       "        <td>2003</td>\n",
       "        <td>2.0</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(7, 'Sons and Lovers ', 1960, 1.0),\n",
       " (1, 'Day of the Painter  ', 1960, 1.0),\n",
       " (3, 'The Empire Strikes Back ', 1980, 1.0),\n",
       " (8, 'Raging Bull ', 1980, 2.0),\n",
       " (6, 'Mystic River    ', 2003, 2.0)]"
      ]
     },
     "metadata": {},
     "execution_count": 213
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "source": [
    "%sql select count(*) from dimAwards3;"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * postgresql://dwhadmin:***@dwhcluster.cdqvmxgabrab.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "1 rows affected.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1316</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(1316,)]"
      ]
     },
     "metadata": {},
     "execution_count": 214
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "source": [
    "%%time\n",
    "\n",
    "qry = \"\"\"\n",
    "    copy dimGenres from 's3://sparkifydend/movies/genres/' \n",
    "    credentials 'aws_iam_role={}' \n",
    "    FORMAT AS PARQUET;\n",
    "\"\"\".format(DWH_ROLE_ARN)\n",
    " \n",
    "%sql $qry"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * postgresql://dwhadmin:***@dwhcluster.cdqvmxgabrab.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "Done.\n",
      "CPU times: user 4.88 ms, sys: 280 µs, total: 5.16 ms\n",
      "Wall time: 1.71 s\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "source": [
    "%sql select * from dimGenres limit 5;"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * postgresql://dwhadmin:***@dwhcluster.cdqvmxgabrab.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "5 rows affected.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>movieid</th>\n",
       "        <th>genre</th>\n",
       "        <th>genreid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>869</td>\n",
       "        <td>Drama</td>\n",
       "        <td>1614907703302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2164</td>\n",
       "        <td>Horror</td>\n",
       "        <td>1614907703310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3052</td>\n",
       "        <td>Comedy</td>\n",
       "        <td>1614907703318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>4224</td>\n",
       "        <td>Thriller</td>\n",
       "        <td>1614907703326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>5476</td>\n",
       "        <td>Horror</td>\n",
       "        <td>1614907703334</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(869, 'Drama', 1614907703302),\n",
       " (2164, 'Horror', 1614907703310),\n",
       " (3052, 'Comedy', 1614907703318),\n",
       " (4224, 'Thriller', 1614907703326),\n",
       " (5476, 'Horror', 1614907703334)]"
      ]
     },
     "metadata": {},
     "execution_count": 216
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "source": [
    "%sql select count(*) from dimGenres;"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * postgresql://dwhadmin:***@dwhcluster.cdqvmxgabrab.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "1 rows affected.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>22084</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(22084,)]"
      ]
     },
     "metadata": {},
     "execution_count": 217
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "source": [
    "%%sql\n",
    "INSERT INTO dimDate (date_key, year, month, day, week)\n",
    "SELECT DISTINCT(rate_time)                                       AS date_key,\n",
    "       EXTRACT(year FROM rate_time)                              AS year,\n",
    "       EXTRACT(month FROM rate_time)                             AS month,\n",
    "       EXTRACT(day FROM rate_time)                               AS day,\n",
    "       EXTRACT(week FROM rate_time)                              AS week\n",
    "FROM dimRatings;"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * postgresql://dwhadmin:***@dwhcluster.cdqvmxgabrab.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "85043 rows affected.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 218
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "source": [
    "%sql select * from dimDate limit 5;"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * postgresql://dwhadmin:***@dwhcluster.cdqvmxgabrab.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "5 rows affected.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>date_key</th>\n",
       "        <th>year</th>\n",
       "        <th>month</th>\n",
       "        <th>day</th>\n",
       "        <th>week</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2000-07-30 18:56:33</td>\n",
       "        <td>2000</td>\n",
       "        <td>7</td>\n",
       "        <td>30</td>\n",
       "        <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2000-07-26 14:46:26</td>\n",
       "        <td>2000</td>\n",
       "        <td>7</td>\n",
       "        <td>26</td>\n",
       "        <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1996-10-17 12:51:34</td>\n",
       "        <td>1996</td>\n",
       "        <td>10</td>\n",
       "        <td>17</td>\n",
       "        <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1996-06-22 10:59:28</td>\n",
       "        <td>1996</td>\n",
       "        <td>6</td>\n",
       "        <td>22</td>\n",
       "        <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-09-27 18:31:15</td>\n",
       "        <td>2016</td>\n",
       "        <td>9</td>\n",
       "        <td>27</td>\n",
       "        <td>39</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(datetime.datetime(2000, 7, 30, 18, 56, 33), 2000, 7, 30, 30),\n",
       " (datetime.datetime(2000, 7, 26, 14, 46, 26), 2000, 7, 26, 30),\n",
       " (datetime.datetime(1996, 10, 17, 12, 51, 34), 1996, 10, 17, 42),\n",
       " (datetime.datetime(1996, 6, 22, 10, 59, 28), 1996, 6, 22, 25),\n",
       " (datetime.datetime(2016, 9, 27, 18, 31, 15), 2016, 9, 27, 39)]"
      ]
     },
     "metadata": {},
     "execution_count": 219
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "source": [
    "%sql select count(*) from dimDate;"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * postgresql://dwhadmin:***@dwhcluster.cdqvmxgabrab.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "1 rows affected.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>85043</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(85043,)]"
      ]
     },
     "metadata": {},
     "execution_count": 220
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "source": [
    "%%time\n",
    "\n",
    "qry = \"\"\"\n",
    "    copy dimmovies0 from 's3://sparkifydend/movies/movies/' \n",
    "    credentials 'aws_iam_role={}' \n",
    "    FORMAT AS PARQUET;\n",
    "\"\"\".format(DWH_ROLE_ARN)\n",
    " \n",
    "%sql $qry"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * postgresql://dwhadmin:***@dwhcluster.cdqvmxgabrab.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "Done.\n",
      "CPU times: user 6.26 ms, sys: 0 ns, total: 6.26 ms\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "source": [
    "%%sql\n",
    "INSERT INTO dimMovies (movieId, title, year)\n",
    "SELECT movieId                                                      AS movieId,\n",
    "       substring(title, 0, length(title)-6)                         AS title, \n",
    "       substring(title, length(title)-4, 4)                         AS year\n",
    "FROM dimMovies0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * postgresql://dwhadmin:***@dwhcluster.cdqvmxgabrab.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "9742 rows affected.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 223
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "source": [
    "%sql select * from dimMovies limit 5;"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * postgresql://dwhadmin:***@dwhcluster.cdqvmxgabrab.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "5 rows affected.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>movieid</th>\n",
       "        <th>title</th>\n",
       "        <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>47</td>\n",
       "        <td>Seven (a.k.a. Se7en)</td>\n",
       "        <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>123</td>\n",
       "        <td>Chungking Express (Chung Hing sam lam)</td>\n",
       "        <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>203</td>\n",
       "        <td>To Wong Foo, Thanks for Everything! Julie Newmar</td>\n",
       "        <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>273</td>\n",
       "        <td>Mary Shelley&#x27;s Frankenstein (Frankenstein)</td>\n",
       "        <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>341</td>\n",
       "        <td>Double Happiness</td>\n",
       "        <td>1994</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(47, 'Seven (a.k.a. Se7en)', '1995'),\n",
       " (123, 'Chungking Express (Chung Hing sam lam)', '1994'),\n",
       " (203, 'To Wong Foo, Thanks for Everything! Julie Newmar', '1995'),\n",
       " (273, \"Mary Shelley's Frankenstein (Frankenstein)\", '1994'),\n",
       " (341, 'Double Happiness', '1994')]"
      ]
     },
     "metadata": {},
     "execution_count": 224
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "source": [
    "%sql select count(*) from dimMovies;"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * postgresql://dwhadmin:***@dwhcluster.cdqvmxgabrab.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "1 rows affected.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>9742</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(9742,)]"
      ]
     },
     "metadata": {},
     "execution_count": 225
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Summary\n",
    "* In this project, I implemented two methods to read data from S3 by Spark and Redshift. After loading data from S3 using Spark, I did data quality check and data cleaning using Spark DF and Spark SQL. Then uploaded table to S3 in parquet format.\n",
    "* Amazon S3 is selected as the data lake tool to store the raw csv and parquet staging data before the data is uploaded to the Amazon Redshift data warehouse. \n",
    "* Parquet is selected as the data format for the staging data in S3 because it is in columnar storage and minimizes latency, thus allowing a more efficient data retrieval and processing.\n",
    "* Apache Spark as a distributed data processing framework allows us to efficiently load and transform huge datasets from the raw datasource to the S3 data lake and load to the Redshift data warehouse.\n",
    "* I also created fact and dimension tables after reading parquet format data from S3 into redshift. When reading parquet data, the data type must match between parquet data and tables to be inserted.\n",
    "* The data should be updated based on the MovieLens datasets.\n",
    "* How I would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x. \n",
    "   - Writing data by partitions to S3 and distributing data to different nodes in redshift by distkey and sortkey. Writing data by partitions in s3 can improve the speed a lot. Redshift is a cloud data warehouse that is optimized for aggregation and read-heavy workloads.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "   - Using Airflow to do the management. Creating Airflow allowed us to programmatically schedule our workflows and monitor them via the built-in Airflow user interface.\n",
    " * The database needed to be accessed by 100+ people.\n",
    "   - Amazon Redshift, in which this data model is hosted, allows up to 500 concurrent users accessing the database.\n",
    "   - Users can connect to the data model with Amazon QuickSight to create dashboards and analyze the dataset.\n",
    "   - We can also manage user access and permission with the AWS IAM, so that we can control which users can access which dashboards and the underlying dataset."
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}